{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from collections import Counter\n",
    "import time\n",
    "import re\n",
    "import chardet\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Загружаем стоп-слова один раз (за пределами функций)\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "    stop_words = set(stopwords.words('russian'))\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "\n",
    "# Функция для чтения файла\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "    encoding = chardet.detect(raw_data)['encoding']\n",
    "    with open(file_path, 'r', encoding=encoding or 'utf-8', errors='ignore') as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "# Функция для подсчета слов (с фильтрацией)\n",
    "def word_count(text, stop_words):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return Counter(filtered_words)\n",
    "\n",
    "\n",
    "# Функция для подсчета фраз\n",
    "def phrase_count(text, n, stop_words):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    phrases = ngrams(filtered_words, n)\n",
    "    return Counter(phrases)\n",
    "\n",
    "\n",
    "# Функция-обработчик для подсчета слов/фраз в процессе\n",
    "def process_text(args):\n",
    "    part, stop_words, count_type, n = args\n",
    "    if count_type == \"word\":\n",
    "        return word_count(part, stop_words)\n",
    "    elif count_type == \"phrase\":\n",
    "        return phrase_count(part, n, stop_words)\n",
    "\n",
    "\n",
    "# Основная функция для многопоточной обработки\n",
    "def parallel_count(file_path, num_processes, count_type=\"word\", n=2):\n",
    "    text = read_file(file_path)\n",
    "    text_length = len(text)\n",
    "    chunk_size = text_length // num_processes\n",
    "    chunks = [text[i:i + chunk_size] for i in range(0, text_length, chunk_size)]\n",
    "\n",
    "    args_list = [(chunk, stop_words, count_type, n) for chunk in chunks]\n",
    "\n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "        results = pool.map(process_text, args_list)\n",
    "\n",
    "    total_count = Counter()\n",
    "    for count in results:\n",
    "        total_count.update(count)\n",
    "    return total_count\n",
    "\n",
    "\n",
    "# Функция для последовательной обработки\n",
    "def sequential_count(file_path, count_type=\"word\", n=2):\n",
    "    text = read_file(file_path)\n",
    "    if count_type == \"word\":\n",
    "        return word_count(text, stop_words)\n",
    "    elif count_type == \"phrase\":\n",
    "         return phrase_count(text, n, stop_words)\n",
    "\n",
    "def visualize_results(results, title, top_n=10):\n",
    "    if not results:\n",
    "        print(\"No results to visualize.\")\n",
    "        return\n",
    "\n",
    "    most_common = results.most_common(top_n)\n",
    "    if isinstance(most_common[0][0], tuple): # для фраз\n",
    "         labels = [' '.join(phrase) for phrase, _ in most_common]\n",
    "    else: # для слов\n",
    "        labels = [word for word, _ in most_common]\n",
    "    values = [count for _, count in most_common]\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.bar(labels, values)\n",
    "    plt.xlabel(\"Words/Phrases\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    FILE_PATH = \"109472392.txt\"  # Замените путь к вашему файлу\n",
    "    NUM_PROCESSES = 4\n",
    "    \n",
    "    # Последовательный подсчет слов\n",
    "    start_time = time.time()\n",
    "    seq_result_words = sequential_count(FILE_PATH, count_type=\"word\")\n",
    "    seq_time_words = time.time() - start_time\n",
    "    print(f\"Последовательный подсчет слов занял {seq_time_words:.2f} секунд.\")\n",
    "\n",
    "    # Параллельный подсчет слов\n",
    "    start_time = time.time()\n",
    "    parallel_result_words = parallel_count(FILE_PATH, NUM_PROCESSES, count_type=\"word\")\n",
    "    parallel_time_words = time.time() - start_time\n",
    "    print(f\"Параллельный подсчет слов занял {parallel_time_words:.2f} секунд.\")\n",
    "\n",
    "    print(f\"Ускорение (слова): {seq_time_words / parallel_time_words:.2f}x\")\n",
    "\n",
    "    # Топ 10 самых частых слов\n",
    "    print(\"\\nТоп 10 самых частых слов:\")\n",
    "    for word, count in parallel_result_words.most_common(10):\n",
    "        print(f\"{word}: {count}\")\n",
    "\n",
    "    # Визуализируем результаты подсчета слов\n",
    "    visualize_results(parallel_result_words, \"Топ 10 самых частых слов\")\n",
    "    # Последовательный подсчет фраз (биграмм)\n",
    "    start_time = time.time()\n",
    "    seq_result_phrases = sequential_count(FILE_PATH, count_type=\"phrase\", n=2)\n",
    "    seq_time_phrases = time.time() - start_time\n",
    "    print(f\"\\nПоследовательный подсчет фраз (биграмм) занял {seq_time_phrases:.2f} секунд.\")\n",
    "\n",
    "     # Параллельный подсчет фраз (биграмм)\n",
    "    start_time = time.time()\n",
    "    parallel_result_phrases = parallel_count(FILE_PATH, NUM_PROCESSES, count_type=\"phrase\", n=2)\n",
    "    parallel_time_phrases = time.time() - start_time\n",
    "    print(f\"Параллельный подсчет фраз (биграмм) занял {parallel_time_phrases:.2f} секунд.\")\n",
    "\n",
    "    print(f\"Ускорение (фразы): {seq_time_phrases / parallel_time_phrases:.2f}x\")\n",
    "\n",
    "    # Топ 10 самых частых фраз (биграмм)\n",
    "    print(\"\\nТоп 10 самых частых фраз (биграмм):\")\n",
    "    for phrase, count in parallel_result_phrases.most_common(10):\n",
    "        print(f\"{' '.join(phrase)}: {count}\")\n",
    "\n",
    "    # Визуализируем результаты подсчета фраз\n",
    "    visualize_results(parallel_result_phrases, \"Топ 10 самых частых фраз (биграмм)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
